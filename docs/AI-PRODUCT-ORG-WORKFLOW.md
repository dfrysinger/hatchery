# AI Product Organization â€” Operating Workflow

> **Version:** 1.0-draft
> **Status:** Council Review Pending
> **Last Updated:** 2026-02-05

A complete operating manual for running an autonomous AI product organization inside Discord + Clawdbot. This workflow governs how ideas become shipped features through structured council deliberation, sprint execution, and quality gates.

---

## Table of Contents

1. [Organization Design](#1-organization-design)
2. [Decision Authority (RACI)](#2-decision-authority-raci)
3. [Discord Server Structure](#3-discord-server-structure)
4. [The Workflow Pipeline](#4-the-workflow-pipeline)
5. [Worker Protocol (TDD)](#5-worker-protocol-tdd)
6. [The Judge's Playbook](#6-the-judges-playbook)
7. [Cost Governance](#7-cost-governance)
8. [Clawdbot Configuration](#8-clawdbot-configuration)
9. [Failure Recovery](#9-failure-recovery)
10. [Artifact Templates](#10-artifact-templates)
11. [Implementation Roadmap](#11-implementation-roadmap)

---

## 1. Organization Design

### 1.1 Permanent Seats (Agents)

| Seat | Model | Account Tier | Primary Role |
|------|-------|-------------|--------------|
| **Opus (Judge/CPO)** | Claude Opus 4.5 | Max | Orchestrator, final arbiter, CPO tiebreaker |
| **Claude** | Claude Opus 4.5 | Max | Panelist â€” product quality, UX coherence, narrative |
| **ChatGPT** | GPT-5.2 | $20/mo | Panelist â€” systems thinking, workflow rigor, edge cases |
| **Gemini** | Gemini 3 Pro | $20/mo | Panelist â€” implementation realism, integration, test strategy |
| **Grok** | Grok | $20/mo | Panelist â€” adversarial review, failure modes, cost, abuse paths |

### 1.2 Dynamic Hats (Role Overlays)

Hats are NOT separate agents â€” they're prompt instructions applied when the Judge dispatches work. Each council member adopts the assigned hat's perspective while retaining their natural strengths.

| Hat | Emoji | Focus |
|-----|-------|-------|
| **Product Manager (PM)** | ğŸ© | User value, requirements, acceptance criteria, UX, market fit |
| **Engineering Lead (EL)** | ğŸ”§ | Architecture, feasibility, scalability, code quality, implementation |
| **Security Researcher (SEC)** | ğŸ”’ | Threat modeling, attack surfaces, auth, data handling, abuse cases |
| **QA Lead** | ğŸ§ª | Test strategy, edge cases, integration testing, quality gates |

**How hats activate:** The Judge's dispatch message includes `HAT: <role>`. Council members respond through that lens. The hat is in the dispatch, not the channel â€” this avoids context loss from channel-hopping and saves tokens.

### 1.3 Scrum Team (Execution)

| Role | Model | Count | Purpose |
|------|-------|-------|---------|
| **Engineering Lead** | Claude Sonnet 4.5 | 1 (dedicated) | Task assignment, code review, integration testing, worker management |
| **Workers** | Claude Sonnet 4.5 | 5 | TDD implementation, unit testing, bug fixes |

**Key design choice:** The EL is a **6th Sonnet agent**, NOT a council member doing double duty. This keeps the council available for high-leverage decisions and prevents Claude from becoming a bottleneck.

---

## 2. Decision Authority (RACI)

Clear authority prevents endless debate. When in doubt, check this table.

| Decision | Responsible | Accountable | Consulted | Informed |
|----------|------------|-------------|-----------|----------|
| Initiative worth council time | Judge | Human | â€” | Council |
| PRD acceptance | Council (PM hat) | Judge | Human | Workers |
| Architecture acceptance | Council (EL hat) | Judge | Human | EL |
| Security requirements | Council (SEC hat) | Judge | Human | EL |
| Task breakdown & sizing | EL | Judge | Council (quick review) | Workers |
| Technical approach per task | EL | EL | â€” | Workers |
| Implementation details | Worker | EL | â€” | â€” |
| Code merge readiness | EL | EL | PM (acceptance criteria only) | Judge |
| Release readiness | Council (all hats) | Judge | Human | EL, Workers |
| Tiebreaker (any dispute) | Judge | Judge | â€” | All |

### Dispute Resolution Protocol

1. **Disagreement detected** between EL and PM (or between council members)
2. **One structured rebuttal round** â€” each party writes a â‰¤200 word case
3. **Judge decides** within 60 seconds, citing rationale
4. **Decision is final** and recorded in `#decisions-log`

No appeals. No re-litigation. Move forward.

---

## 3. Discord Server Structure

### 3.1 Channel Map

```
ğŸ›ï¸ COUNCIL
â”œâ”€â”€ #council-lobby        â€” Judge announcements, phase transitions, human requests
â”œâ”€â”€ #deliberation         â€” Forum: council discusses dispatched topics (1 post per topic)
â”œâ”€â”€ #decisions-log        â€” Read-only: Judge posts final decisions + rationale
â”œâ”€â”€ #council-votes        â€” Quick polls when preference sensing is useful

ğŸ“‹ PRODUCT
â”œâ”€â”€ ğŸ“‹ prds               â€” Forum: each PRD is a post (tags: Draft / Review / Approved / Rejected)
â”œâ”€â”€ ğŸ“‹ roadmap            â€” Forum: release milestones and feature groupings

ğŸ”§ SCRUM
â”œâ”€â”€ #standup              â€” EL posts assignments, workers report status (daily summaries)
â”œâ”€â”€ #code-review          â€” MR submissions, review discussions, approval/rejection
â”œâ”€â”€ ğŸ“‹ sprint-tasks       â€” Forum: each task is a post (tags: Todo / In Progress / Review / Done / Blocked)
â”œâ”€â”€ ğŸ“‹ bugs               â€” Forum: bug reports (tags: P0 / P1 / P2 / In Progress / Resolved)

ğŸ§ª QUALITY
â”œâ”€â”€ #test-results         â€” Automated test output, integration test reports
â”œâ”€â”€ #release-candidates   â€” RC announcements + council review threads

ğŸ“Š RELEASES
â”œâ”€â”€ #release-notes        â€” Published release notes for the human
â”œâ”€â”€ ğŸ“‹ releases           â€” Forum: each release with changelog and review trail

ğŸ”§ OPS
â”œâ”€â”€ #alerts               â€” CI failures, gateway issues, cron reminders
â”œâ”€â”€ #audit-log            â€” "Who did what" summaries (bot-posted)
```

### 3.2 Permission Model

| Role | Council Channels | Product | Scrum | Quality | Releases | Ops |
|------|-----------------|---------|-------|---------|----------|-----|
| Human | Full access | Full | Full | Full | Full | Full |
| Judge | Full access | Full | Read + post | Full | Full | Full |
| Council Members | Post in #deliberation | Read | Read only | Read | Read | Read |
| EL | Read #decisions-log | Read | Full access | Full | Post | Read |
| Workers | None | Read PRDs | Post in scrum channels | Post test results | None | None |

### 3.3 Discord Features Used

| Feature | Purpose |
|---------|---------|
| **Forum channels** | Structured tracking with status tags (PRDs, tasks, bugs, releases) |
| **Forum tags** | Status workflow (Draft â†’ Review â†’ Approved â†’ Done) |
| **Threads** | Per-item discussions, keeps main channels clean |
| **Pinned messages** | Latest approved artifacts in each channel |
| **Polls** | Quick council preference sensing (Judge still decides) |
| **Reactions** | âœ… approve, ğŸš© flag concern, ğŸ›‘ block, ğŸ‘€ reviewing |
| **Roles** | Visual identification + permission control |

---

## 4. The Workflow Pipeline

### Overview

The pipeline has **3 council gates** (expensive, high-leverage) and **multiple execution phases** (cheap, worker-driven).

```
Intake â†’ [GATE 1: PRD + Architecture] â†’ Sprint Planning â†’ [GATE 2: Task Review] â†’
Sprint Execution â†’ Testing â†’ [GATE 3: Release Review] â†’ Demo
```

---

### Phase 0 â€” Intake (Free)

**Who:** Human (or lightweight bot triage)
**Where:** `#council-lobby`
**What:** Human describes a feature idea or problem

**Output:** Raw feature request. Judge decides if it's worth council time.

**Judge actions:**
1. Acknowledge receipt
2. Ask 3-5 clarifying questions (scope, constraints, success metrics)
3. Once clarified, write a `OnePager.md` summary
4. Decide: proceed to Gate 1, or defer

---

### GATE 1 â€” PRD + Architecture Review (Council)

**Cost:** 4 panelist calls + 1 Judge synthesis = **5 calls**
**Time:** 30-45 minutes max
**Where:** `#deliberation` forum post

This gate combines PM hat (PRD) and EL hat (architecture) into a single council round to save budget. Council members respond with BOTH perspectives in one report.

**Judge dispatches:**
```
COUNCIL:PROCEED
Topic: <one-line description>
Slug: <topic-slug>
Round: 1
HAT: PM + EL (combined)
Scope: Write a combined assessment covering:
  1. PRD perspective: requirements, user value, acceptance criteria, risks
  2. Engineering perspective: architecture, feasibility, dependencies, test strategy
Context: <OnePager.md contents>
Deadline: 5 minutes
```

**Each panelist produces:** `~/clawd/shared/reports/Round1_<AgentName>.md`

**Judge synthesizes into:**
- `PRD.md` â†’ posted to ğŸ“‹ prds forum
- `Solution.md` â†’ posted to ğŸ“‹ prds forum (same thread)
- `SecurityNotes.md` (from Grok's adversarial review)

**Gate decision:** Judge posts to `#decisions-log`:
```
GATE 1 PASSED/FAILED
Topic: <slug>
Rationale: <why>
Action: Proceed to Sprint Planning / Revise and resubmit
```

**Human touchpoint:** Human reviews PRD + Solution in the forum post. Approves or requests changes.

---

### Phase 1 â€” Sprint Planning (EL + Judge)

**Cost:** 0-1 council calls (Judge + EL only; council consulted only if complex)
**Where:** `ğŸ“‹ sprint-tasks` forum

**EL produces:**
- Release breakdown (R1, R2, ...)
- Per-release task list with:
  - Task ID, title, description
  - Acceptance criteria (tied to PRD requirements)
  - Test requirements
  - Files likely touched
  - Dependencies on other tasks
  - Definition of done
  - Estimated complexity (S/M/L)

**Output:** One forum post per task in `ğŸ“‹ sprint-tasks`, tagged `Todo`.

---

### GATE 2 â€” Task Review (Council, Quick)

**Cost:** 4 panelist calls + 1 synthesis = **5 calls**
**Time:** 15-20 minutes (this is a sanity check, not a deep dive)

**Judge dispatches** the full task list to council with:
```
COUNCIL:PROCEED
HAT: PM
Topic: <slug> â€” Task Coverage Review
Question: Do these tasks fully cover the PRD requirements?
  Missing scenarios? Over-engineering? Under-scoping?
```

**Output:** Approved task backlog, or specific gaps to address.

---

### Phase 2 â€” Sprint Execution (Workers + EL)

**Cost:** 0 council calls
**Where:** `#standup`, `#code-review`, `ğŸ“‹ sprint-tasks`

This is where the 5 Sonnet workers do the actual building. See [Section 5: Worker Protocol](#5-worker-protocol-tdd) for details.

**EL responsibilities during sprint:**
1. Assign tasks to workers via `sessions_send`
2. Monitor `#standup` for status updates
3. Review MRs in `#code-review`
4. Provide code-level feedback
5. Check acceptance criteria alignment (PM perspective)
6. Escalate to Judge only for disputes or architectural questions
7. Take over tasks where workers are stuck after 2 attempts

**Parallel execution:** Up to 5 tasks in flight simultaneously. EL manages branch conflicts and dependency ordering.

---

### Phase 3 â€” Testing (Workers + EL)

**Cost:** 0 council calls
**Where:** `#test-results`, `ğŸ“‹ bugs`

1. **Workers test their own tasks** â€” run unit tests, verify acceptance criteria
2. **Workers report** results to `#test-results`
3. **EL runs integration tests** across the full release
4. **Bugs filed** to `ğŸ“‹ bugs` forum, assigned back to the worker who wrote the code
5. **Fix cycle:** Worker fixes â†’ EL re-tests â†’ repeat until clean
6. **Stuck workers** (2 attempts): EL fixes, Judge reviews

**Release Candidate criteria:**
- All unit tests passing
- Integration tests passing
- No P0 or P1 bugs open
- All acceptance criteria verified

---

### GATE 3 â€” Release Candidate Review (Council)

**Cost:** 4 panelist calls + 1 synthesis = **5 calls** (batched multi-hat)
**Time:** 30 minutes max
**Where:** `#release-candidates`

**Judge dispatches ONE round** with all hats combined:
```
COUNCIL:PROCEED
HAT: EL + PM + SEC (all perspectives)
Topic: <slug> â€” Release Candidate Review
Deliverables:
  1. Engineering review: code quality, architecture compliance, tech debt
  2. Product review: all PRD requirements met? UX acceptable?
  3. Security review: threat mitigations in place? New attack surfaces?
Context: <RC_Checklist.md with test results, known issues, changes>
```

**Gate decision options:**
- âœ… **Ship it** â†’ proceed to demo
- ğŸ”„ **Conditional** â†’ specific issues sent back to scrum team (one more cycle)
- ğŸ›‘ **Reject** â†’ fundamental problems, needs re-architecture (rare)

**Human touchpoint:** Judge announces "Ready for demo" in `#release-notes`.

---

### Phase 4 â€” Release Demo

**Where:** `#release-notes`
**What:** Human tests the release candidate live

**Output:** Ship approval, or bug list for one more fix cycle.

---

### Budget Summary Per Feature

| Phase | Council Calls | Notes |
|-------|:------------:|-------|
| Intake | 0 | Judge only |
| Gate 1: PRD + Architecture | 5 | Combined round |
| Sprint Planning | 0-1 | EL + Judge; council only if complex |
| Gate 2: Task Review | 5 | Quick sanity check |
| Sprint Execution | 0 | Workers + EL only |
| Testing | 0 | Workers + EL only |
| Gate 3: RC Review | 5 | Batched multi-hat round |
| **Total** | **15-16** | ~4 calls per $20/mo model per feature |

This is **3-4x cheaper** than sequential hat rounds, with no loss of quality â€” council members are smart enough to wear multiple hats simultaneously when asked.

---

## 5. Worker Protocol (TDD)

### 5.1 Task Assignment

Workers receive tasks from the EL via `sessions_send`:

```
TASK:ASSIGNED
Task-ID: <id>
Title: <title>
Description: <what to build>
Acceptance Criteria:
  - AC1: <criterion>
  - AC2: <criterion>
  - ...
Test Requirements:
  - <what must be tested>
Files: <likely files to touch>
Branch: feature/<task-id>-<slug>
Context: <relevant PRD sections, architecture notes>
```

### 5.2 TDD Cycle

```
1. READ task spec + acceptance criteria thoroughly
2. CREATE feature branch: feature/<task-id>-<slug>
3. WRITE failing tests first (RED phase)
   - One test per acceptance criterion minimum
   - Edge case tests for boundary conditions
4. IMPLEMENT minimum code to pass tests (GREEN phase)
5. REFACTOR for clarity, readability, and maintainability
6. RUN full test suite â€” fix any regressions
7. COMMIT with conventional commit message:
   feat(<scope>): <description>
   Refs: TASK-<id>
8. POST MR to #code-review:
   [TASK-<id>] <title>
   Branch: feature/<task-id>-<slug>
   Tests: X passing, Y new
   Files: <list>
   Summary: <what and why>
9. WAIT for review feedback
10. ADDRESS feedback (up to 2 revision rounds)
11. If STUCK after 2 attempts:
    POST to #standup: ğŸ”´ BLOCKED: TASK-<id> â€” <what's stuck and why>
    (EL will take over)
```

### 5.3 Status Updates

Workers post to `#standup` using these prefixes:

```
ğŸŸ¢ STARTED: TASK-<id> â€” <title>
ğŸ”„ PROGRESS: TASK-<id> â€” <what's done, what's next>
ğŸ“ MR READY: TASK-<id> â€” submitted to #code-review
ğŸ”´ BLOCKED: TASK-<id> â€” <reason>
ğŸ› BUG FILED: BUG-<id> â€” <description>
âœ… DONE: TASK-<id> â€” merged
```

### 5.4 Failure Protocol

When a worker fails a task after 2 attempts:
1. Worker writes a **short postmortem** (â‰¤100 words): what was tried, what failed, what they think the issue is
2. Postmortem posted to `#standup`
3. EL takes over the task
4. Judge (CPO) reviews EL's implementation
5. Postmortem informs future task scoping (lessons learned â†’ `KNOWLEDGE.md`)

---

## 6. The Judge's Playbook

### 6.1 Dispatch Protocol

For each council gate:

```
1. Announce phase in #council-lobby
2. Create forum post in #deliberation (or #release-candidates for Gate 3)
3. Send COUNCIL:PROCEED via sessions_send to each panelist:
   - HAT instruction(s)
   - PHASE name
   - TOPIC slug + round number
   - Full context (PRD, code summary, previous decisions)
   - DEADLINE (5 minutes standard)
4. Monitor for ACKs:
   - No ACK in 60s â†’ re-ping once
   - Still no ACK in 60s â†’ note absence, continue with available panelists
5. At 4 minutes: reminder to panelists who haven't filed reports
6. At 5 minutes: proceed with available reports
7. Read reports from ~/clawd/shared/reports/Round{N}_{AgentName}.md
8. Synthesize into structured output
9. Post synthesis to #decisions-log (and relevant forum post)
10. Address any DISSENT: or QUESTION: tags from panelists
11. Gate decision: PASSED / CONDITIONAL / FAILED with rationale
12. Check if human feedback needed â†’ wait or proceed
```

### 6.2 EL Management Protocol

During sprint phases, the Judge manages the Sonnet EL:

```
1. Provide EL with approved task list from ~/clawd/shared/tasks/
2. EL breaks down and assigns tasks to workers
3. Judge monitors #standup for blockers
4. Judge intervenes only for:
   - Architectural disputes
   - Worker 2-strike escalations
   - PM vs EL disagreements
   - Scope creep detection
5. Judge does NOT micromanage implementation
```

### 6.3 Synthesis Template

```markdown
## Synthesis â€” [Topic] Round [N]

### Individual Assessment
**Claude:** [strengths, gaps, notable insights]
**ChatGPT:** [strengths, gaps, notable insights]
**Gemini:** [strengths, gaps, notable insights]
**Grok:** [strengths, gaps, notable insights]

### Consensus Points
- [items all/most panelists agree on]

### Divergence Points
- [item] â€” Claude/ChatGPT say X, Gemini/Grok say Y
  â†’ Judge ruling: [decision + rationale]

### My Analysis
[Judge's independent assessment â€” not just averaging the panelists]

### Decisions
1. [decision with rationale]
2. [decision with rationale]

### Open Questions
- [unresolved items for human or next round]

### DISSENT Responses
- [response to any DISSENT: tags]

### QUESTION Responses
- [answers to any QUESTION for Judge: tags]
```

---

## 7. Cost Governance

### 7.1 Core Principles

1. **Council only meets at gates.** Three gates per feature, max. Everything else is async EL + workers.
2. **Artifact-first rule.** No council discussion without a structured document to react to.
3. **Single-round debate.** One rebuttal round for disagreements. Judge decides after that.
4. **Combined hats save money.** Asking for PM + EL + SEC in one dispatch is 4 calls. Doing them sequentially is 12.
5. **Sonnet does the drafting.** Use cheap models to write first drafts of PRDs/solutions, then council critiques (expensive refinement, cheap generation).

### 7.2 Tiered Engagement

| Decision Complexity | Who | Cost |
|-------------------|-----|------|
| Full council deliberation | 4 panelists + Judge | 5 calls |
| Quick review (consensus expected) | 2 panelists + Judge | 3 calls |
| Routine code review | EL only | 0 external calls |
| Bug triage | EL + 1 panelist | 1 call |
| Tiebreaker | Judge only | 0 external calls |
| Worker task execution | Workers | Sonnet-tier only |

### 7.3 Monthly Capacity Estimates

Assuming ~100 quality interactions per $20/month model:

| Activity | Calls per Model | Features/Month |
|----------|:--------------:|:--------------:|
| Full feature (3 gates) | ~4 per gate Ã— 3 = 12 | ~8 features |
| Quick feature (1-2 gates) | ~4-8 | ~12-25 features |
| Bug fix / patch (no council) | 0 | Unlimited |

**Budget alarm:** Judge tracks API usage. If any model is at 70% monthly usage, switch to reduced engagement (2 panelists instead of 4, skip Gate 2).

---

## 8. Clawdbot Configuration

### 8.1 Agent Architecture

```
11 agents total:
â”œâ”€â”€ judge (agent: Opus 4.5) â€” orchestrator
â”œâ”€â”€ council-claude (agent: Opus 4.5) â€” panelist
â”œâ”€â”€ council-chatgpt (agent: GPT-5.2) â€” panelist
â”œâ”€â”€ council-gemini (agent: Gemini 3 Pro) â€” panelist
â”œâ”€â”€ council-grok (agent: Grok) â€” panelist
â”œâ”€â”€ scrum-el (agent: Sonnet 4.5) â€” engineering lead
â”œâ”€â”€ worker-1 through worker-5 (agent: Sonnet 4.5) â€” developers
```

### 8.2 Shared Filesystem

```
~/clawd/shared/
â”œâ”€â”€ ROLES.md                  â€” Hat definitions and behavioral instructions
â”œâ”€â”€ WORKFLOW.md               â€” This document (phase state machine)
â”œâ”€â”€ KNOWLEDGE.md              â€” Accumulated project knowledge
â”œâ”€â”€ DECISIONS.md              â€” Decision log
â”œâ”€â”€ CONTEXT.md                â€” Current project context
â”œâ”€â”€ reports/                  â€” Council round reports
â”‚   â””â”€â”€ Round{N}_{Agent}.md
â”œâ”€â”€ prds/                     â€” PRD documents
â”‚   â””â”€â”€ {feature-slug}.md
â”œâ”€â”€ tasks/                    â€” Task specifications
â”‚   â””â”€â”€ TASK-{id}.md
â”œâ”€â”€ bugs/                     â€” Bug reports
â”‚   â””â”€â”€ BUG-{id}.md
â””â”€â”€ releases/                 â€” Release documentation
    â””â”€â”€ {version}/
        â”œâ”€â”€ CHANGELOG.md
        â”œâ”€â”€ RC_CHECKLIST.md
        â””â”€â”€ REVIEW.md
```

### 8.3 Communication Flow

```
Human â†’ #council-lobby â†’ Judge
Judge â†’ sessions_send â†’ Council panelists (for gates)
Judge â†’ sessions_send â†’ EL (for sprint management)
EL â†’ sessions_send â†’ Workers (for task assignment)
Workers â†’ #standup, #code-review â†’ EL (status, MRs)
EL â†’ Judge (escalations only)
Judge â†’ #decisions-log â†’ All (decisions)
Judge â†’ #release-notes â†’ Human (demo readiness)
```

### 8.4 Channel Bindings

Each Discord channel is bound to the appropriate agent(s):

- **Council channels** (`#council-lobby`, `#deliberation`, `#decisions-log`) â†’ Judge
- **Scrum channels** (`#standup`, `#code-review`, `ğŸ“‹ sprint-tasks`, `ğŸ“‹ bugs`) â†’ EL
- **Quality channels** (`#test-results`, `#release-candidates`) â†’ EL + Judge
- **Release channels** (`#release-notes`) â†’ Judge
- **Forum channels** (PRDs, roadmap, releases) â†’ Judge (posting), all (reading)

Workers communicate via `sessions_send`, not Discord channels directly, to reduce noise.

---

## 9. Failure Recovery

### 9.1 Worker Failures

| Scenario | Response |
|----------|----------|
| Worker stuck after 2 attempts | EL takes over; worker writes postmortem |
| Worker produces code that breaks integration tests | Bug filed, assigned back to worker |
| Worker unresponsive (session crash) | EL spawns replacement worker, reassigns task |
| All workers stuck on same issue | EL escalates to Judge; may need architecture change |

### 9.2 EL Failures

| Scenario | Response |
|----------|----------|
| EL can't resolve integration issue | Escalate to Judge; Judge may convene emergency council |
| EL disagrees with PM on acceptance | One rebuttal round â†’ Judge decides |
| EL session crashes | Judge spawns new EL agent, provides full context |

### 9.3 Council Failures

| Scenario | Response |
|----------|----------|
| Panelist doesn't ACK dispatch | Re-ping once; proceed without after 2 minutes |
| Panelist produces garbage report | Judge ignores it, notes quality issue |
| All panelists disagree | Judge makes independent decision, records rationale |
| Judge session crashes | Human restarts; Judge reads DECISIONS.md for continuity |

### 9.4 Infrastructure

| Scenario | Response |
|----------|----------|
| Clawdbot gateway restart | Sessions resume; Judge checks for interrupted phases |
| Git conflict between workers | EL resolves; may reassign conflicting tasks sequentially |
| Rate limit hit on $20/mo model | Judge switches to reduced engagement mode |

---

## 10. Artifact Templates

### 10.1 OnePager.md

```markdown
# One-Pager: [Feature Name]

**Author:** [Human / Bot]
**Date:** [YYYY-MM-DD]

## Problem
[What pain point or opportunity are we addressing?]

## Target Users
[Who benefits?]

## Proposed Solution
[High-level description]

## Success Metrics
[How do we know this worked?]

## Constraints
[Budget, timeline, technical, compliance]

## Non-Goals
[What we're explicitly NOT doing]

## Open Questions
[Unknowns that need resolution]
```

### 10.2 PRD.md

```markdown
# PRD: [Feature Name]

**Version:** [N]
**Status:** [Draft / Review / Approved]
**Owner:** Judge (synthesized from council)

## Goal
[One sentence]

## Non-Goals
[Explicit exclusions]

## User Personas & Jobs-to-be-Done
[Who and what they're trying to accomplish]

## Requirements

### Must Have
- [REQ-1] [requirement] â€” AC: [acceptance criteria]
- [REQ-2] ...

### Should Have
- [REQ-N] ...

### Could Have
- [REQ-N] ...

## UX Notes
[Interaction model, key flows]

## Metrics
[Success criteria with measurable targets]

## Risks & Assumptions
[What could go wrong; what we're assuming is true]

## Security Considerations
[Data handling, auth, abuse potential â€” from Grok's review]

## Out of Scope
[Explicit boundaries]
```

### 10.3 Solution.md

```markdown
# Solution: [Feature Name]

**Version:** [N]
**PRD:** [link]

## Architecture Overview
[High-level design with component diagram if useful]

## Data Flow
[How data moves through the system]

## APIs / Interfaces
[New or modified interfaces]

## Dependencies
[External services, libraries, other features]

## Test Strategy
- Unit: [approach]
- Integration: [approach]
- E2E: [approach]

## Rollout Plan
[How to deploy safely]

## Observability
[Logging, monitoring, alerting]

## Known Tradeoffs
[Decisions made and why]

## Cost Considerations
[Resource usage, API costs, scaling]
```

### 10.4 Task Spec

```markdown
# TASK-[ID]: [Title]

**Release:** R[N]
**Status:** [Todo / In Progress / Review / Done / Blocked]
**Assigned:** [worker-N]
**Complexity:** [S / M / L]
**Depends On:** [TASK-IDs or "none"]

## Description
[What to build]

## Acceptance Criteria
- [ ] AC1: [criterion]
- [ ] AC2: [criterion]

## Test Requirements
- [ ] [what must be tested]

## Files Likely Touched
- [file paths]

## Branch
`feature/TASK-[ID]-[slug]`

## Definition of Done
- [ ] Tests written and passing
- [ ] Code reviewed by EL
- [ ] Acceptance criteria verified
- [ ] No regressions in test suite
```

### 10.5 RC_Checklist.md

```markdown
# Release Candidate: [Version]

**Date:** [YYYY-MM-DD]
**Release:** R[N]
**Status:** [Review / Approved / Rejected]

## Test Results
- Unit tests: [X/Y passing]
- Integration tests: [X/Y passing]
- Known failures: [list or "none"]

## Changes Included
- TASK-1: [title] â€” [status]
- TASK-2: [title] â€” [status]

## Known Issues
- [issue description] â€” [severity] â€” [mitigation]

## Security Checklist
- [ ] No new unauthenticated endpoints
- [ ] Input validation on all user-facing inputs
- [ ] Secrets management verified
- [ ] No sensitive data in logs

## Rollback Plan
[How to revert if something breaks]

## Demo Script
1. [Step 1]
2. [Step 2]
```

---

## 11. Implementation Roadmap

### Week 1: Foundation
- [ ] Create Discord server categories and channels per Section 3
- [ ] Set up forum channels with status tags
- [ ] Configure Discord roles and permissions
- [ ] Set up Clawdbot multi-agent configuration (11 agents)
- [ ] Write `ROLES.md` with hat definitions
- [ ] Deploy this workflow document as `WORKFLOW.md` in shared directory

### Week 2: Council Protocol
- [ ] Write Judge's `AGENTS.md` with full orchestration protocol
- [ ] Write panelist `AGENTS.md` files with hat-switching + report protocol
- [ ] Test one full council round (Gate 1 style) with a sample topic
- [ ] Refine dispatch format, timing, and report templates
- [ ] Verify `sessions_send` reliability between all council agents

### Week 3: Worker Pipeline
- [ ] Write EL's `AGENTS.md` with task management protocol
- [ ] Write worker `AGENTS.md` with TDD protocol
- [ ] Set up shared git repository access for all agents
- [ ] Test: task assignment â†’ TDD â†’ MR â†’ review â†’ merge cycle
- [ ] Test: worker failure â†’ EL takeover flow
- [ ] Refine status update format

### Week 4: Integration
- [ ] End-to-end test: idea â†’ PRD â†’ tasks â†’ code â†’ test â†’ release
- [ ] Measure actual council call costs against budget estimates
- [ ] Optimize timing (are 5-minute deadlines right?)
- [ ] Document lessons learned
- [ ] First real feature through the pipeline

---

## Appendix A: Glossary

| Term | Definition |
|------|-----------|
| **Gate** | A council review point where work is approved, conditionally approved, or rejected |
| **Hat** | A role overlay that defines the perspective a council member adopts |
| **EL** | Engineering Lead â€” the Sonnet agent managing the worker team |
| **MR** | Merge Request â€” a worker's code submission for review |
| **RC** | Release Candidate â€” code that has passed all tests and is ready for council review |
| **Dispatch** | The Judge sending a `COUNCIL:PROCEED` message to panelists |
| **Postmortem** | A worker's brief explanation of why they couldn't complete a task |

---

*This is a living document. Update after each retrospective.*
